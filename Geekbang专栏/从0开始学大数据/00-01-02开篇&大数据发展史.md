# 00-01-02开篇&大数据发展史

## 00--开篇词--为什么要懂大数据技术
软件编程的核心价值，就是把显示世界的业务操作搬到计算机上没通过计算机软件和网络进行业务和数据处理。

想让计算机软件、互联网应用继续提高工作效率，需要发掘出用户自己都没有发现的需求，洞悉用户自己都不了解的自己。

未来软件开发将是面向ai编程，软件的核心业务逻辑和价值将围绕机器学习的结果展开。数据会越来越成为公司的核心资产和主要竞争力，公司的业务展开和产品进化也越来越朝着如何利用好数据价值的方向发展。

## 大数据发展史

通常所说的大数据技术，是从Google在2004年前后发表的三篇论文：  
分布式文件系统GFS、大数据分布式计算框架MapRdeduce、NoSQL数据库系统Big Table

搜索引擎的主要两件事情：网页抓取，索引构建，这个过程大量的数据需要储存和计算，三篇论文也是为了解决这些问题，一个文件系统、一个计算框架、一个数据库系统  

2004年大多数公司的关注点在与如何提升单机的性能、寻找更贵更好的服务器，Google的思路是部署在一个大规模的服务器集群上，通过分布式的方式将海量数据存储在这个集群上，然后利用集群上的所有机器进行数据计算，这样就不需要买很多服务器，只要把普通的服务器组织在一起就可以了。

2006年从初步实现类似GFS和MapReduce功能的开源搜索引擎Nutch中分离，单独开发维护，成为后来的Hadoop，包括Hadoop分布式文件系统HDFS和大数据计算引擎MapReduce。

从Hadoop源码中得到的思考：我们所开发的软件价值在哪里，真正需要使用软件实现价值的地方在哪里，应该更关注业务，理解业务，有价值导向，用自己的技术为公司创造价值，进而实现自己的人生价值。

Hadoop发布后被陆续使用，2008年成为Apache的顶级项目，但是Yahoo的人觉着使用MapReduce进行大数据编程太麻烦，就开发了pig，一种类SQL的语法，使用pig脚本描述要对大数据集上进行的操作，编译后生成MapReduce程序然后再Hadoop上运行。

编写pig脚本需要学习新的脚本语法，Facebook发布了Hive，可以使用SQL语法来进行大数据计算，然后hive把SQL语句转化为MapReduce计算程序。  
hive的出现极大程度的降低了Hadoop的使用难度，这个时候数据库的分析师和工程师是可以无门槛的使用大数据进行数据分析处理，2011年Facebook大规模应用之后关于Hadoop的周边产品开始出现，sqoop：专门将关系数据库中的数据导入到Hadoop，flume：针对大规模日志进行分布式收集、聚合、传输，oozie：MapReduce的工作流调度引擎。

Hadoop早期MapReduce是执行引擎也是资源调度框架，调度无服务器集群的资源，2012年yarn项目将执行引擎和资源调度分离开，成为大数据平台上最主流的资源调度系统。  
同年uc伯克利amp实验室的spark开始崭露头角：因为MapReduce进行机器学习的性能很差，机器学习需要迭代很多次，然而MapReduce每执行一次map和reduce计算都需要重新启动一次作业，带来很多的无谓的损耗，并且MapReduce主要使用磁盘作为存储介质，而2012年内存已经突破容量的成本限制，成为数据运行过程中的主要存储介质。

MapReduce和spark这类计算框架处理的业务场景为批处理计算，通常针对以天为单位产生的数据进行计算，中间计算需要花的时间几十分钟，计算的数据是历史数据，也称为大数据离线计算。  
对于实时产生的大量数据进行即时计算，称谓大数据流计算，使用storm，flink，spark streaming等流计算框架，处理在线实时产生的数据，也称为大数据实时计算。  

典型的大数据业务场景：使用批处理处理历史全量数据，使用流计算处理实施新增数据，flink可以同时支持流式计算和批处理计算。

nosql系统处理的也主要是大规模海量数据的存储和访问，2011年涌现出HBASE，Cassandra等产品，HBASE是从Hadoop中分离出来，基于HDFS的nosql系统。

从软件发展的历史中拓展的思考：在历史前进的逻辑中前进，在时代发展的潮流中发展。

大数据引擎或大数据框架，处理的主要场景：数据分析、数据挖掘、机器学习数据分析主要使用hive、spark SQL等SQL引擎，数据挖掘和机器学习有专门的TensorFlow、mahout、mllib等大数据总是也要存入分布式文件系统HDFS，有序调度MapReduce和spark作业，才可以吧执行结果写入到各个应用系统的数据库中。大数据平台↓。

![image-20200405190858603](C:\Users\lyd\AppData\Roaming\Typora\typora-user-images\image-20200405190858603.png)

数据仓库是解决数据问题的方案和方法，大数据是具体的实现技术，大数据和关系型数据库都可以实现数据仓库。



## 从搜索引擎到人工智能搜索引擎时代

Google存储着全世界几乎所有可访问的网页，为了存储这些文件，Google开发了GFS，Google文件系统，使用数千台服务器上的数万块磁盘统一管理，当做一个文件系统，统一存储所有这些网页文件。

不光要做存储，还要搭建搜索引擎，对文件中的单词做词频统计，根据PageRank算法计算网页排名，这就需要对数万块磁盘上的文件进行处理，MapReduce开发满足这些需求，之后诞生了Hadoop。

数据仓库时代：Facebook推出hive，在Hadoop上进行SQL操作，使用更低廉的价格获得更高的数据存储和计算能力。将运行日志，应用采集数据，数据仓库数据放到一起进行计算分析。

数据挖掘时代：除了数据统计，还希望从中挖掘更多的价值。关联分析、推荐商品的关联推荐不同人的特征标签，用户画像关系图谱挖掘，描绘社交网络人际关系网

机器学习时代：收集历史数据，统计其规律，进而预测正在发生的事情。AlphaGo、聊天机器人、人工智能ai

未来的软件开发不再是需求-分析-设计-实现的确定性过程，而是定义问题和目标，收集数据，提供数据，再由神经网络不断探索最优解的非确定性过程。