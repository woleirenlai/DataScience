# 科学规范的A/B测试流程

* 准备工作：数据和测试平台
* 规范流程：
  * 确定目标和假设
  * 确定指标
    * 选取评价指标和护栏指标
    * 表征指标的波动性
      * 统计公式
      * A/A测试
      * Bootstrapping
  * 确定试验单位
  * 样本量估算
    * α
    * Power
    * 方差Variance
    * 期望的最小差值δ
  * 随机分组
    * 推荐50%/50%
  * 测试的时间估算
    * 样本量
    * 周期性变化
    * 流量使用率
  * 实施测试
  * 分析测试结果
    * 合理性检验
    * 选择合适的假设检验方法
    * 分析测试结果得出推断结论

# 03确定目标和假设

* 将产品/业务的变化作为原因，将业务目标变成结果，业务问题就转换为因果推断，对于A/B测试来说就找到了测试的目标，而假设就是既包含想要做出的改变又包含期望达到的结果。

* 确定目标和假设--以某月付费音乐APP提高营收为例
  * **分析问题，确定想要达到的结果**--竞品对比分析发现用户留存率低于行业平均，用户留存率是目前存在的问题。
  * **提出解决业务问题的大致方案**--影响用户留存的原因有很多，进一步分析发现APP缺少便利的产品功能，大致解决方案为增加产品功能来提升用户留存。
  * **从大致解决方案中提取出具体假设**--通过增加具体产品功能如自动播放来提高用户留存。
    * 提升用户留存这一目标需要被量化，按照具体业务场景，用户的每月按时付费预定就是留存，将下个月的续订率定义为用户留存。
  * 最终的假设：每个专辑/歌单后增加自动播放下一专辑/歌单的功能，可以提高用户下个月的续订率。
* 好的假设来源于用户调研、数据挖掘、观察经验等，明确包含可能的原因和结果，可以被证伪，有定量的指标。
* A/B 测试是因果推断，首先要确定原因和结果，目标决定了结果（用户留存）， 假设决定了原因（增加自动播放的功能），目标和假设对 A/B 测试来说缺一不可。
* A/B测试的指标分为评价指标和护栏指标
  * 评级指标通常是短期的比较敏感、有很强操作性的指标，如点击率、转化率、人均使用时长等，能够反映A/B测试结果的指标。
  * 护栏指标属于AB测试中的合理性检验，作为辅助保证测试质量，在评价指标选择后确定。用来衡量测试是否符合业务的长期目标，不会因为优化短期指标而打乱长期目标，并且确保从统计上尽量减少出现各种偏差，得到尽可能值得信任的实验结果。
* 评价指标的选择方法
  * 可归因性，选择的业务指标的变化（结果）必须要可以归因到实验中的变量（原因）。
  * 可测量性，好的假设需要能够被量化。
  * 敏感性和稳定性，如果实验中的变量变化了，评价指标要能敏感地做出相应的变化；如果其他因素变化了，评价指标要能保持相应的稳定性。
    * 用 A/B 测试来检测单次的变化时（如单次推送 / 邮件）一般选用短期效果的指标，因为长期效果目标通常对单次变化并不敏感。用 A/B 测试来检测连续的、永久的变化时（比如增加产品功能），可以选用长期效果的指标。
    * 通常使用A/A测试测量稳定性，使用回溯性分析表征敏感性。
      * A/A测试也将测试对象分为测试组和实验组，但是两组对象拥有完全相同的体验，如果 A/A 测试结果发现两组的指标有显著不同，就说明要么分组分得不均匀，每组的数据分布差异较大；要么选取的指标波动范围太大，稳定性差。
      * 回溯性分析是一般在没有之前的实验数据或者因为某些原因如时间不够没有办法跑新的实验，可以进行的历史数据分析，也就是在分析之前不同的产品变化时，看感兴趣的指标是否有相应的变化。
* 具体的评价指标的选取
  * 根据业务或产品所处阶段的目标来确定评价指标
    * 起步阶段的新用户相关，拉新过程中的各种点击率转化率，发展成熟期的现有用户的使用和留存，关注用户平均使用时间和频率、产品特定功能的使用率、用户留存率。
  * 目标比较抽象时采用定性+定量结合方法
    * 用户满意度这个抽象指标，先进行定性分析如问卷调查用户调研，进行分组，再对不同组的用户做定量的用户使用习惯数据分析。
  * 条件允许时通过公开或者非公开的渠道，参考其他公司相似的实验或者研究，根据自己的情况借鉴。
    * 《精益数据分析》

# 04确定指标

* 对于同一目标，有多个重要评价指标时，需要综合多个指标，建立总体评价标准OEC(Overall Evaluation Criteria)
  * 最常见的OEC是结合变化带来潜在收益和损失的OEC，此处损失还可能是护栏指标。
  * 不同指标的单位、大小可能不在一个尺度上，需要先要对各个指标进行归一化处理，使其取值都在一定的范围内，比如[0,1]， 之后再进行结合，从而剔除指标单位/大小的影响。
* 评价指标的值会因各种因素的影响而发生波动，统计学中指标的波动性通常用其平均值和平均值的标准差来表示，变量平均值的标准差又叫做标准误差，评价指标的正常波动范围就是置信区间。
* 使用统计公式和实践经验计算波动范围
  * 置信区间 = 样本均值 ± Z分数*标准误差
    * 一般情况下选用 95% 的置信区间，对应的 z 分数为 1.96。
    * 概率类指标的标准误差 = 事件发生的概率*(1-事件发生的概率)/样本大小后开根号。
    * 均值类指标的标准误差 = 样本标准差的平方(方差)/样本大小后开根号 

* 根据实践经验确定波动范围
  * A/A测试：多个不同样本的A/A测试，分别计算每个样本的指标大小之后从小到大排列，去除最小和最大2.5%剩下就是95%置信区间
  * Bootstrapping算法：一个样本很大的A/A测试，在大样本中进行随机可置换抽样，之后按A/A测试步骤。适用于分布比较复杂的指标。
  * 概率类或者均值类的这些符合二项分布或者正态分布的指标，建议同时用统计公式和 Bootstrapping 两种方法来计算。
* 护栏指标的选取
  * 业务品质层面：保证用户体验的同时，兼顾盈利能力和用户的参与度
    * 网络延迟：网页加载时间、APP响应时间等
    * 闪退率
    * 人均指标
      * 收入角度：人均花费、人均利润
      * 用户参与赌：人均使用时长、人均使用频率
  * 统计品质层面：尽可能多地消除偏差，使实验组和对照组尽可能相似
    * 实验/对照组样本量大小的比例
    * 实验/对照组中特征的分布

# 05选取实验单位

* 实验单位都是用户的行为，原因是在产品、营销、业务上做的调整，本质上都是为了观察用户的行为是否有相应的变化。
* 常用的实验单位
  * 用户层面，准确度从高到低：用户id；匿名id（Cookies）；设备id；IP地址。
    * 适合变化易被用户察觉的A/B测试。
  * 访问层面：用户的每次访问作为一个最小单位，访问开始以进入这个网站或APP的那一瞬间为记录，访问结束以用户在某个网站或APP连续30分钟无任何动作为结束。
    * 适合变化不易被用户察觉的A/B测试。
    * 一个用户经常访问时，会有多个不同的访问id，进行A/B测试时可能会出现一个用户即在实验组又在对照组的情况。
  * 页面层面：把每一个新的页面浏览作为最小单位，新的是指即使是相同的页面，被相同的人在不同时间浏览也会算作不同的页面。
    * 适合变化不易被用户察觉的A/B测试。
  * 实验单位的准确度越高，A/B测试的结果准确度越高
  * 从用户层面到访问层面再到页面层面，实验单位颗粒度越来越细，相应地可以从中获得更多的样本量
* 选择实验单位的原则
  * 保证用户体验的一致性。
    * 如果 A/B 测试中的变化是用户可以察觉到的，那么实验单位就要选择用户层面。
  * 实验单位应与评价指标的单位保持一致
  * 样本数量要尽可能多。
    * 绝对不能因为要获得更多的样本量，就选择颗粒度更细的实验单位，而不考虑前面两个原则。