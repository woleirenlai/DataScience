# 06-HDFS依然是存储的王者

Google大数据的三驾马车第一个就是GFS谷歌文件系统，而Hadoop的第一个产品是HDFS，分布式文件存储是分布式计算的基础。

HDFS作为最早的大数据存储系统，存储着宝贵的数据资产，各种新的算法、框架要想得到人们的广泛使用，就必须支持HDFS才能获取已经存储在里面的数据，所以大数据技术越发展，新技术越多，HDFS支持越多，HDFS或许不是最好的大数据存储技术，但依然是最重要的大数据存储技术。

Hadoop分布式文件系统HDFS的设计目标是管理数以千计的服务器、数以万计的磁盘，将这些服务器计算资源当做一个单一的存储系统进行管理，对应用程序提供数以pb计的存储容量，让应用程序像使用普通文件系统一样存储大规模的文件数据。

**设计思路**

核心原理：RAID设计理念扩大到整个分布式服务器集群

RAID是将数据分片后在多块磁盘上并发进行读写访问，从而提高存储容量，加快访问速度，并通过数据的冗余校验提高数据的可靠性。  
HDFS是在一个大规模分布式服务器集群上，对数据分片后进行读写和冗余存储。因为HDFS可以部署在一个比较大的服务器集群上，集群中所有服务器的磁盘都可以供HDFS使用，所以整个HDFS的存储空间可以达到pb级。

HDFS架构：

![06-1](https://github.com/woleirenlai/Images/blob/master/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/06/06-01.jpg)

HDFS的两个关键组件：DataNode和NameNode

DataNode负责文件数据的存储和读写，HDFS将文件数据分割成若干数据块block，每个DataNode存储一部分数据块，这样文件就分布存储在整个HDFS服务器集群中。  
应用程序客户端可以并行对这些数据块进行访问，使得HDFS可以服务器集群规模上实现数据并行访问，提高了访问速度。  
HDFS的DataNode服务器会有很多台，几百到几千的规模，每台服务器会有很多磁盘，整个集群的存储容量大概在几pb到几百pb。

NameNode负责整个分布式文件系统的元数据MetaData的管理，即文件路径名、数据块的ID、存储位置信息，相当于操作系统文件分配表FAT的角色。  
HDFS会将一个数据块复制为多份，缺省情况为3份，并将多份相同的数据块存储在不同的服务器上，甚至不同的机架上，如果有磁盘损坏甚至某个DataNode服务器宕机甚至某个交换机宕机时，客户端会查找其备份的数据进行访问。

例如：

![06-2](https://github.com/woleirenlai/Images/blob/master/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/06/06-02.jpg)

图中，对于文件 /users/sameerp/data/part-0，其复制备份数设置为 2，存储的 BlockID 分别为 1、3。

Block1 的两个备份存储在 DataNode0 和 DataNode2 两个服务器上，Block3 的两个备份存储 DataNode4 和 DataNode6 两个服务器上，其中一台服务器宕机后，每个数据块都至少还有一个备份存在，不会影响对文件 /users/sameerp/data/part-0 的访问。

HDFS一般的访问模式通过MapReduce程序在计算时读取，MapReduce对输入数据进行分片，通常一个分片就是一个数据块，每个数据块分配一个计算进程，这样就可以同时启动多个进程对一个HDFS文件的多个数据块进行并发访问。
与RAID相同，数据分成若干数据块后存储到不同服务器上，可以实现数据大容量存储，而且不同分片的数据可以并行进行读写操作，进而实现高速访问。

**高可用性设计**

1.数据存储容错  
对于磁盘受环境或者老化导致的数据错乱，HDFS对于存储在DataNode上的数据块，计算并存储校验和checksum，在读取数据的时候，重新计算读取出来的数据校验和，如果校验不正确就抛出异常，应用程序捕获异常后就到其他DataNode上读取备份数据。

2.磁盘故障容错  
DataNode检测到本机上某块磁盘损坏，会将该磁盘上存储的所有BolckID报告给NameNode，NameNode检查这些数据块还在哪些DataNode上有备份，通知相应的DataNode服务器将对应的数据块复制到其他服务器上，以保证block的备份要求。

3.DataNode故障容错  
DataNode通过心跳和NameNode保持通信，如果DataNode超时未发送心跳，NameNode会认为该DataNode已经宕机，并立刻查找这个DataNode上存储的数据块有哪些，在哪些服务器上还有备份，并通知这些服务器子再复制一份到其他服务器上，保证HDFS存储的数据块备份符合用户设置的数目，再次宕机也不会丢失数据。

4.NameNode故障容错NameNode是整个HDFS的核心，记录了所有的文件路径、数据块存储信息，目前采用主从热备的方式提供高可用服务。

![06-3](https://github.com/woleirenlai/Images/blob/master/%E4%BB%8E0%E5%BC%80%E5%A7%8B%E5%AD%A6%E5%A4%A7%E6%95%B0%E6%8D%AE/06/06-03.png)

整个服务器集群部署两台NameNode服务器，一主一备，两台服务器通过zookeeper选举（争夺znode锁资源）决定谁是主服务器，DataNode会向两个NameNode都发送心跳数据，只有主NameNode才能向DataNode返回控制信息。  
正常运行时，主从NameNode通过shared edits共享存储系统同步文件系统的元数据信息（文件分配表信息），主NameNode宕机时，从NameNode通过zookeeper成为主NameNode，并保证HDFS集群的元数据信息。

软件系统的可用性很重要，性能、体验差或许可以忍受，如果经常出故障导致不可用，并出现重要数据丢失，就很麻烦，并且分布式系统可能出故障的地方很多，内存、CPU、主板、磁盘，服务器、网络、机房，这些地方出故障都可能会导致软件系统不可用，甚至数据永久丢失。

一般来说，**保证系统可用性的策略有冗余备份、失效转移、降级限流。**

冗余备份：任何程序和数据都至少要有一个备份，程序至少要部署到两台服务器上，数据至少要备份到另一台服务器上。  
大型的互联网企业会建设多个数据中心，数据中心之间相互备份，异地多活，用户的请求可能被分发到任何一个数据中心去，遭遇自然灾害时也保证高可用。

失效转移：无法访问程序或数据时，需要将访问请求转移到备份的程序或数据所在的服务器。  
需要注意失效判别，NameNode这样的主从服务器管理同一份数据，如果服务器错误的以主服务器宕机而接管集群管理，就会导致主从服务器一起对DataNode发送指令，进而导致集群混乱，这也是引入zookeeper的原因。

降级限流：大量的数据处理请求到达时，由于计算资源有限，无法处理这么大的量，金额导致资源耗尽系统崩溃，这种情况下可以拒绝部分请求，进行限流，也可以关闭部分功能，降低资源消耗，进行降级。  
超出负载能力的访问流量何时到来根本无法预料，需要提前做好准备，遇到突发高峰流量，就可以立即启动限流。  
降级通常是为了可预知的场景准备，电商促销，为了保障核心功能例如下单功能可以使用，可以关闭部分非重要功能，例如商品评价。