# 13-数据变换

正态分布是正常的情况下呈现的分布情况。

例如考试成绩，在正态分布中，大部分人的成绩会集中在中间的区域，少部分人处于两头的位置。

## 数据变换在数据分析中的角色

如果考试中， A 考了 80 分，B 也考了 80 分，但前者是百分制，后者 500 分是满分，把从这两个渠道收集上来的数据进行集成、挖掘，就算使用效率再高的算法，结果也不是正确的。因为这两个渠道的分数代表的含义完全不同。

所以有时候数据变换比算法选择更重要，数据错了，算法再正确也是错的。

将不同渠道的数据统一到一个目标数据库里，就需要进行数据变换。

在数据变换前，我们需要先:  
对字段进行筛选  
对数据进行探索和相关性分析  
选择算法模型（暂不需要进行模型计算）  
针对算法模型对数据的需求进行数据变换，从而完成数据挖掘前的准备工作。

数据变换是数据准备的重要环节，它通过**数据平滑、数据聚集、数据概化和规范化等方式**将数据转换成适用于数据挖掘的形式。

常见的变换方法：

* **数据平滑**：去除数据中的噪声，将连续数据离散化。可以采用分箱、聚类和回归的方式进行数据平滑；
* **数据聚集**：对数据进行汇总，在 SQL 中有一些聚集函数可以操作，比如 Max() 反馈某个字段的数值最大值，Sum() 返回某个字段的数值总和；
* **数据概化**：将数据由较低的概念抽象成为较高的概念，减少数据复杂度，即用更高的概念替代更低的概念。比如说上海、杭州、深圳、北京可以概化为中国。
* **数据规范化**：使属性数据按比例缩放，这样就将原来的数值映射到一个新的特定区域中。常用的方法有最小—最大规范化、Z—Score 规范化、按小数定标规范化等；
* **属性构造**：构造出新的属性并添加到属性集中。会用到特征工程的知识，通过属性与属性的连接构造新的属性，其实就是特征工程。比如说，数据表中统计每个人的英语、语文和数学成绩，你可以构造一个“总和”这个属性，来作为新属性。这样“总和”这个属性就可以用到后续的数据挖掘计算中。

## 数据规范化的几种方法

1.Min-max 规范化

Min-max 规范化方法是将原始数据变换到[0,1]的空间中。用公式表示：

新数值 =（原数值 - 极小值）/（极大值 - 极小值）。

2.Z-Score 规范化

假设 A 与 B 的考试成绩都为 80 分，A 的考卷满分是 100 分（及格 60 分），B 的考卷满分是 500 分（及格 300 分）。虽然两个人都考了 80 分，但是 A 的 80 分与 B 的 80 分代表完全不同的含义。

Z-Score可以用相同的标准来比较成绩。 

定义：新数值 =（原数值 - 均值）/ 标准差。

假设 A 所在的班级平均分为 80，标准差为 10。B 所在的班级平均分为 400，标准差为 100。

那么 A 的新数值 =(80-80)/10=0，B 的新数值 =(80-400)/100=-3.2。

那么在 Z-Score 标准下，A 的成绩会比 B 的成绩好。

 Z-Score 的优点是算法简单，不受数据量级影响，结果易于比较。不足在于，它需要数据整体的平均值和方差，而且结果没有实际意义，只是用于比较。

3.小数定标规范化

小数定标规范化就是通过移动小数点的位置来进行规范化。

小数点移动多少位取决于属性 A 的取值中的最大绝对值。举个例子，比如属性 A 的取值范围是 -999 到 88，那么最大绝对值为 999，小数点就会移动 3 位，即新数值 = 原数值 /1000。那么 A 的取值范围就被规范化为 -0.999 到 0.088。