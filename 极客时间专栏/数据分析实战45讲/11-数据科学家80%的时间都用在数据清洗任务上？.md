# 11-数据科学家80%的时间都用在数据清洗任务上？

在采集完数据之后，下一步需要进行数据挖掘前期的准备工作，我们会遇到各种各样的数据，分析前需要投入大量的时间和精力把数据整理成自己需要的样子。

收集整理数据一定要对数据做标注，数据表头很重要，缺少列名的标注就不知道每列数据代表的含义，无法理解业务价值，以及这些数据的正确性。

## 数据质量的准则

可以将数据清洗的规则总结为4个关键点：**完全合一**

1.**完**整性：单条数据是否存在空值，统计的字段是否完善。  
2.**全**面性：观察某一列的全部数值，比如在 Excel 表中，选中一列，可以看到该列的平均值、最大值、最小值。可以通过常识来判断该列是否有问题，比如：数据定义、单位标识、数值本身。  
3.**合**法性：数据的类型、内容、大小的合法性。比如数据中存在非 ASCII 字符，性别存在了未知，年龄超过了 150 岁等。  
4.**唯**一性：数据是否存在重复记录，数据通常来自不同渠道的汇总，重复的情况是常见的。行数据、列数据都需要是唯一的，比如一个人不能重复记录多次，且一个人的体重也不能在列指标中重复记录多次。

这四个关键点可以解决数据清洗中遇到的大部分问题。

## 清洗数据

使用Python的Pandas工具。

### 1.完整性

**1.1缺失值**

数值的缺失有可能是因为数据量比较大，有些数据没有采集到的，通常的处理方法：

* 删除，删除缺失数据的记录
* 均值。使用当前列的均值
* 高频，使用当前列中频率最高的数据

使用 df[column].fillna() 方法填充空缺值，带inplace = True 参数表示替换。

使用高频数据填充时，先通过 value_counts 获取 字段最高频次，然后再对字段中缺失的数据用最高频次进行填充。

**1.2空行**

数据中的一个空行，除了 index 之外，全部的值都是 NaN。Pandas 的 read_csv() 并没有可选参数来忽略空行，需要在数据被读入之后再使用 dropna() 进行处理，删除空行。

```python
# 删除全空的行
df.dropna(how='all',inplace=True) 
```

### 2.全面性

**2.1列数据单位不统一**

例如表示重量的列，有的单位是千克（kgs），有的单位是磅（lbs）。

需要做统一化处理，将kg作为统一单位，将lbs转化为kg。

```python
# 获取 weight 数据列中单位为 lbs 的数据
rows_with_lbs = df['weight'].str.contains('lbs').fillna(False)
print df[rows_with_lbs]
# 将 lbs转换为 kgs, 2.2lbs=1kgs
for i,lbs_row in df[rows_with_lbs].iterrows():
  # 截取从头开始到倒数第三个字符之前，即去掉lbs。
  weight = int(float(lbs_row['weight'][:-3])/2.2)
  df.at[i,'weight'] = '{}kgs'.format(weight) 
```

### 3.合理性

**非ASCII字符**

出现在姓名中的非 ASCII 的字符，使用删除或者替换的方式来解决

```python
# 删除非 ASCII 字符
df['first_name'].replace({r'[^\x00-\x7F]+':''}, regex=True, inplace=True)
df['last_name'].replace({r'[^\x00-\x7F]+':''}, regex=True, inplace=True)
```

### 4.唯一性

**4.1一列有多个参数**

例如姓名列（Name）包含了两个参数 Firstname 和 Lastname。为了达到数据整洁目的，需要将 Name 列拆分成 Firstname 和 Lastname 两个字段。使用 Python 的 split 方法，str.split(expand=True)，将列表拆成新的列，再将原来的 Name 列删除。

```python
# 切分名字，删除源数据列
df[['first_name','last_name']] = df['name'].str.split(expand=True)
df.drop('name', axis=1, inplace=True)
```

**4.2重复数据**

使用Pandas 提供的 drop_duplicates() 来删除重复数据。

## 养成数据审核的习惯

没有高质量的数据，就没有高质量的数据挖掘，而数据清洗是高质量数据的一道保障。